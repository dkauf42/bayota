{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from amplpy import AMPL, Environment\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseexppath = '/Users/Danny/Desktop/CATEGORIES/CAREER_MANAGEMENT/CRC_ResearchScientist_Optimization/Optimization_Tool/2_ExperimentFolder/'\n",
    "amplappdir = os.path.join(baseexppath, 'ampl/amplide.macosx64/')\n",
    "projectpath = os.path.join(baseexppath, 'ampl/OptEfficiencySubProblem/')\n",
    "datapath = os.path.join(baseexppath, 'ampl/OptEfficiencySubProblem/data/')\n",
    "\n",
    "# Specify model and data files\n",
    "# f_mod = os.path.join(baseexppath, 'ampl/example/steel3.mod')\n",
    "f_mod = os.path.join(projectpath, 'test4.mod')\n",
    "# f_dat = os.path.join(baseexppath, 'ampl/example/steel3.dat')\n",
    "f_dat = os.path.join(projectpath, 'test4.dat')\n",
    "\n",
    "# Specify AMPL solver to be used\n",
    "f_minos_solver = os.path.join(projectpath, 'amplide.macosx64/minos')\n",
    "f_gurobi_solver = os.path.join(projectpath, 'amplide.macosx64/gurobi')\n",
    "f_solver = f_minos_solver\n",
    "\n",
    "# Data table directories\n",
    "sourcedatadir = os.path.join(baseexppath, 'OptSandbox/data/test_source/')\n",
    "metadatadir = os.path.join(baseexppath, 'OptSandbox/data/test_metadata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up the AMPL environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Danny/Desktop/CATEGORIES/CAREER_MANAGEMENT/CRC_ResearchScientist_Optimization/Optimization_Tool/2_ExperimentFolder/ampl/OptEfficiencySubProblem/amplide.macosx64/minos\n"
     ]
    }
   ],
   "source": [
    "ampl = AMPL(Environment(amplappdir))\n",
    "ampl.setOption('solver', f_solver)\n",
    "value = ampl.getOption('solver')\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl.read(f_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the data tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tables for the set definitions\n",
    "TblBmp = pd.read_csv(os.path.join(sourcedatadir, 'TblBmp.csv'))\n",
    "TblBmpGroup = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpGroup.csv'))\n",
    "TblBmpLoadSourceGroup = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpLoadSourceGroup.csv'))\n",
    "TblBmpType = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpType.csv'))\n",
    "\n",
    "TblLoadSource = pd.read_csv(os.path.join(sourcedatadir, 'TblLoadSource.csv'), skipinitialspace=True)\n",
    "TblLoadSource['loadsource'] = TblLoadSource['loadsource'].str.strip() # There is an extra space after \"Specialty Crop Low\" that needs to be removed.\n",
    "\n",
    "TblLoadSourceGroup = pd.read_csv(os.path.join(sourcedatadir, 'TblLoadSourceGroup.csv'))\n",
    "TblLoadSourceGroupLoadSource = pd.read_csv(os.path.join(sourcedatadir, 'TblLoadSourceGroupLoadSource.csv'))\n",
    "TblLandRiverSegment = pd.read_csv(os.path.join(sourcedatadir, 'TblLandRiverSegment.csv'))\n",
    "\n",
    "TblGeography = pd.read_csv(os.path.join(sourcedatadir, 'TblGeography.csv'))\n",
    "TblGeographyLrSeg = pd.read_csv(os.path.join(sourcedatadir, 'TblGeographyLrSeg.csv'))\n",
    "TblGeographyType = pd.read_csv(os.path.join(sourcedatadir, 'TblGeographyType.csv'))\n",
    "\n",
    "# Data tables for the parameter definitions\n",
    "TblCostBmpLand = pd.read_csv(os.path.join(metadatadir, 'TblCostBmpLand.csv'))\n",
    "TblBmpEfficiency = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpEfficiency.csv'))\n",
    "# Target load reductions ???  (set this ourselves??)\n",
    "TblLandUsePreBmp = pd.read_csv(os.path.join(sourcedatadir, 'TblLandUsePreBmp.csv'))\n",
    "Tbl2010NoActionLoads = pd.read_csv(os.path.join(datapath, '2010NoActionLoads.csv'))\n",
    "\n",
    "# Data table generated by separate python script, the set of load source *groups* where each load source *group* contains one and only one load source\n",
    "singlelsgrpdf = pd.read_csv(os.path.join(datapath, 'single-ls_groups.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instance specifiers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$, the scenario base year (defines the available load source acres ($T$) and their base loads ($\\phi$))<br>\n",
    "$\\kappa$, the cost profile (defines the costs ($c$))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseconditionid = 29\n",
    "costprofileid=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pollutants and Land river segments**\n",
    "\n",
    "$P$, the set of pollutants $p=\\{nitrogen, phosphorous, sediment\\}$ <br>\n",
    "$L$, a set of land river segments $l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PLTNTS   \n",
      "    'N'        \n",
      "    'P'        \n",
      "    'S'        \n",
      "\n",
      "   LRSEGS   \n",
      "    1677       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pltnts = ampl.getSet('PLTNTS')\n",
    "pltnts.setValues(['N', 'P', 'S'])\n",
    "print(pltnts.getValues())\n",
    "\n",
    "lrsegs = ampl.getSet('LRSEGS')\n",
    "lrsegids = TblLandRiverSegment[TblLandRiverSegment['landriversegment']=='N51133RL0_6450_0000'].lrsegid.tolist()\n",
    "lrsegs.setValues(lrsegids)\n",
    "print(lrsegs.getValues())\n",
    "lrsegsetlist = list([int(x) for x in lrsegs.getValues().toPandas().index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Sources and their groups**\n",
    "\n",
    "$\\Lambda$, the set of load sources $\\lambda$ <br>\n",
    "$\\Psi$, the set of all load source *groups* $\\psi$, where $\\psi=\\{\\lambda_{1}, \\lambda_{2}...\\lambda_{m_{\\psi}}\\}\\subseteq\\Lambda$ <br>\n",
    "$\\Psi^{*}$, the set of load source *groups* where each load source *group* contains one and only one load source ($\\Psi^{*}\\subset\\Psi\\quad\\mid\\quad\\left\\vert\\psi^{*}\\right\\vert=1 \\quad\\forall \\psi^{*}\\in\\Psi^{*} $) <br>\n",
    "$\\psi_{\\lambda}^{*}$, the load source *group* containing only the load source $\\lambda$ <br>\n",
    "\n",
    "*Furthermore*, limit the load sources set to only include those that have base loading rates defined in the No Action data, and only those that have an acreage defined in TblLandUsePreBmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadsrcs = ampl.getSet('LOADSRCS')\n",
    "# limit the load sources set to only include those that have \n",
    "#  base loading rates defined in the No Action data, \n",
    "#  and only those that have an acreage defined in TblLandUsePreBmp\n",
    "df = TblLandUsePreBmp[(TblLandUsePreBmp['baseconditionid']==baseconditionid) &\\\n",
    "                      (TblLandUsePreBmp['lrsegid'].isin(lrsegsetlist))].copy()\n",
    "df = singlelsgrpdf[singlelsgrpdf['loadsourceid'].isin(df['loadsourceid'])]\n",
    "loadsrcs.setValues(df.loadsourceid.tolist())\n",
    "loadsrcsetlist = list([int(x) for x in loadsrcs.getValues().toPandas().index])\n",
    "#print(loadsrcs.getValues())\n",
    "\n",
    "loadsrcgrps = ampl.getSet('LOADSRCGRPS')\n",
    "loadsrcgrps.setValues(TblLoadSourceGroup.loadsourcegroupid.tolist())\n",
    "#print(loadsrcgrps.getValues())\n",
    "\n",
    "loadsrcgrping = ampl.getSet('LOADSRCGRPING')\n",
    "loadsrcgrping.setValues(list(zip(TblLoadSourceGroupLoadSource.loadsourcegroupid.tolist(),\n",
    "                             TblLoadSourceGroupLoadSource.loadsourceid.tolist())))\n",
    "#print(loadsrcgrping.getValues())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BMPs and their groups**\n",
    "\n",
    "$B$, a set of BMPs $b$ <br>\n",
    "$\\Gamma$, a set of BMP *groups* $\\gamma$, where $\\gamma=\\{b_{1}, b_{2}...b_{n_{\\gamma}}\\}\\subseteq B$<br>\n",
    "$\\gamma_{b}$, the BMP *group* to which BMP $b$ belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmps = ampl.getSet('BMPS')\n",
    "bmps.setValues(TblBmp.bmpid.tolist())\n",
    "# print(bmps.getValues())\n",
    "\n",
    "bmpgrps = ampl.getSet('BMPGRPS')\n",
    "bmpgrpdf = TblBmpGroup[TblBmpGroup['ruleset']=='spbmpruleset_efficiencybmps']\n",
    "bmpgrps.setValues(bmpgrpdf.bmpgroupid.tolist())\n",
    "# print(bmpgrps.getValues())\n",
    "\n",
    "bmpgrping = ampl.getSet('BMPGRPING')\n",
    "bmpgrping.setValues(list(zip(TblBmp.bmpid.tolist(),\n",
    "                             bmpgrpdf.bmpgroupid.tolist())))\n",
    "# print(bmpgrping.getValues())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c_{b}^{\\kappa}$, the cost per acre of BMP $b$ (for cost profile $\\kappa$) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ampl.getParameter('c')\n",
    "df = TblCostBmpLand[TblCostBmpLand['costprofileid']==costprofileid]\n",
    "c.setValues(dict(zip(df.bmpid, df.totalannualizedcostperunit)))\n",
    "# print(c.getValues())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E_{b,p,l,\\lambda}$, the effectiveness per acre of BMP $b$ on reducing pollutant $p$, in land-river segment $l$ and load source $\\lambda$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 'N', 1677, 1) 0.03\n",
      "(3, 'N', 1677, 2) 0.08\n",
      "(3, 'N', 1677, 3) 0.08\n",
      "(3, 'N', 1677, 4) 0.08\n",
      "(3, 'N', 1677, 5) 0.03\n"
     ]
    }
   ],
   "source": [
    "# Some pre-processing is necessary to build the parameter dictionary\n",
    "effsubtable = TblBmpEfficiency[TblBmpEfficiency['lrsegid'].isin(lrsegsetlist)]\n",
    "# make the pollutant names into an index instead of separate columns\n",
    "listofdataframes = []\n",
    "pltntdict = {'tn': 'N', 'tp': 'P', 'sed': 'S'}\n",
    "for ps in ['tn', 'tp', 'sed']:\n",
    "    bmpeff = effsubtable.loc[:, ['bmpid', 'lrsegid', 'loadsourceid', ps]]\n",
    "    bmpeff['pltnt'] = pltntdict[ps]\n",
    "    bmpeff.rename(columns={ps: 'effvalue'}, inplace=True)\n",
    "    listofdataframes.append(bmpeff)\n",
    "df = pd.concat(listofdataframes)\n",
    "\n",
    "# Retain only those effectivenesses pertaining to loadsources in our set\n",
    "df = df[df['loadsourceid'].isin(loadsrcsetlist)]\n",
    "\n",
    "# Convert groups to dictionary ( with tuple->value structure ) \n",
    "grouped = df.groupby(['bmpid', 'pltnt', 'lrsegid', 'loadsourceid'])\n",
    "Edict = grouped['effvalue'].apply(lambda x: list(x)[0]).to_dict()\n",
    "\n",
    "# display 5 keys for illustration\n",
    "nrandkeys = list(islice(Edict,5))\n",
    "for k, v in zip(nrandkeys, [Edict[x] for x in nrandkeys]):\n",
    "    print(k, v)\n",
    "    \n",
    "E = ampl.getParameter('E')\n",
    "E.setValues(Edict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tau_{l,p}$, the target percent load reduction per pollutant per land river segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1677, 'N'): 0.5, (1677, 'P'): 0.5, (1677, 'S'): 0.5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tau = ampl.getParameter('tau')\n",
    "\n",
    "Taudict = {}\n",
    "for l in lrsegsetlist:\n",
    "    Taudict[(l, 'N')] = 0.5\n",
    "    Taudict[(l, 'P')] = 0.5\n",
    "    Taudict[(l, 'S')] = 0.5\n",
    "display(Taudict)\n",
    "\n",
    "tau.setValues(Taudict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi_{l,\\lambda,p}^{y}$, the base nutrient load per pollutant per load source per land river segment (for year $y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loadsourceid</th>\n",
       "      <th>lrsegid</th>\n",
       "      <th>2010 no action_nloadeos</th>\n",
       "      <th>2010 no action_ploadeos</th>\n",
       "      <th>2010 no action_sloadeos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1677</td>\n",
       "      <td>129.2</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1072.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1677</td>\n",
       "      <td>34949.5</td>\n",
       "      <td>321.2</td>\n",
       "      <td>1092874.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loadsourceid  lrsegid  2010 no action_nloadeos  2010 no action_ploadeos  \\\n",
       "0             1     1677                    129.2                     25.2   \n",
       "1             2     1677                  34949.5                    321.2   \n",
       "\n",
       "   2010 no action_sloadeos  \n",
       "0                   1072.8  \n",
       "1                1092874.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1677, 1, 'N') 129.2\n",
      "(1677, 1, 'P') 25.2\n",
      "(1677, 1, 'S') 1072.8\n",
      "(1677, 2, 'N') 34949.5\n",
      "(1677, 2, 'P') 321.2\n"
     ]
    }
   ],
   "source": [
    "# Some pre-processing is necessary to build the parameter dictionary\n",
    "\n",
    "# Unfortunately, the NoActionLoads table is from the website so doesn't have id numbers.  Let's translate this table to id numbers...\n",
    "\n",
    "# Let's make sure the columns are all lowercase\n",
    "Tbl2010NoActionLoads.columns = map(str.lower, Tbl2010NoActionLoads.columns)\n",
    "\n",
    "# First, let's translate our lrseg list to the fullnames so we can subset it before translating.\n",
    "gtypeid = TblGeographyType[TblGeographyType['geographytypefullname']=='Land River Segment indicating if in or out of CBWS'].geographytypeid.tolist()[0]\n",
    "geolrsegsubtbl = TblGeographyLrSeg.loc[TblGeographyLrSeg['lrsegid'].isin(lrsegsetlist)]\n",
    "geosubtbl = geolrsegsubtbl.merge(TblGeography, on='geographyid', how='inner')\n",
    "lrsegfullnames = geosubtbl[geosubtbl['geographytypeid']==gtypeid].geographyfullname.tolist()\n",
    "\n",
    "loadssubtbl = Tbl2010NoActionLoads[Tbl2010NoActionLoads['geography'].isin(lrsegfullnames)]\n",
    "\n",
    "# Go from load source table with geographyfullname to geographyid\n",
    "includecols = ['geography', 'loadsource', '2010 no action_nloadeos', '2010 no action_ploadeos', '2010 no action_sloadeos']\n",
    "loadssubtbl = loadssubtbl.loc[:, includecols].merge(TblGeography, how='inner',\n",
    "                                                    left_on='geography',\n",
    "                                                    right_on='geographyfullname')\n",
    "loadssubtbl.drop(columns=['geographyname',\n",
    "                          'geographyfullname',\n",
    "                          'geography',\n",
    "                          'geographytypeid'], inplace=True)\n",
    "\n",
    "# Go from load source table with geographyid to lrsegid\n",
    "includecols = ['geographyid', 'lrsegid']\n",
    "loadssubtbl = TblGeographyLrSeg.loc[:,includecols].merge(loadssubtbl, how='inner',\n",
    "                                                         on='geographyid')\n",
    "loadssubtbl.drop(columns=['geographyid'], inplace=True)\n",
    "\n",
    "# Go from LoadSource to loadsourceid\n",
    "includecols = ['loadsourceid', 'loadsource']\n",
    "loadssubtbl = TblLoadSource.loc[:,includecols].merge(loadssubtbl, how='inner',\n",
    "                                                     on='loadsource')\n",
    "loadssubtbl.drop(columns=['loadsource'], inplace=True)\n",
    "display(loadssubtbl.head(2))\n",
    "\n",
    "# only retain loadsources that are represented by a single-ls loadsource group.\n",
    "loadssubtbl = loadssubtbl[loadssubtbl['loadsourceid'].isin(loadsrcsetlist)]\n",
    "\n",
    "# make the pollutant names into an index instead of separate columns\n",
    "listofdataframes = []\n",
    "pcolnames = ['2010 no action_nloadeos', '2010 no action_ploadeos', '2010 no action_sloadeos']\n",
    "pltntdict = {pcolnames[0]: 'N',\n",
    "             pcolnames[1]: 'P',\n",
    "             pcolnames[2]: 'S'}\n",
    "for ps in [pcolnames[0], pcolnames[1], pcolnames[2]]:\n",
    "    llload = loadssubtbl.loc[:, ['lrsegid', 'loadsourceid', ps]]\n",
    "    llload['pltnt'] = pltntdict[ps]\n",
    "    llload.rename(columns={ps: 'loadratelbsperyear'}, inplace=True)\n",
    "    listofdataframes.append(llload)\n",
    "df = pd.concat(listofdataframes)\n",
    "# Convert groups to dictionary ( with tuple->value structure ) \n",
    "grouped = df.groupby(['lrsegid', 'loadsourceid', 'pltnt'])\n",
    "LoadDict = grouped['loadratelbsperyear'].apply(lambda x: list(x)[0]).to_dict()\n",
    "\n",
    "# display 5 keys for illustration\n",
    "nrandkeys = list(islice(LoadDict,5))\n",
    "for k, v in zip(nrandkeys, [LoadDict[x] for x in nrandkeys]):\n",
    "    print(k, v)\n",
    "    \n",
    "phi = ampl.getParameter('phi')\n",
    "phi.setValues(LoadDict)\n",
    "\n",
    "# lrsegfullnames.loc[:,['geographyfullname'].merge(Tbl2010NoActionLoads, left_on=)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{l,\\lambda}^{y}$, the total acres available for land-river segment $l$ and load source $\\lambda$ (for year $y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lrsegid</th>\n",
       "      <th>loadsourceid</th>\n",
       "      <th>acres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3652116</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>37.184830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652117</th>\n",
       "      <td>1677</td>\n",
       "      <td>2</td>\n",
       "      <td>1631.665771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lrsegid  loadsourceid        acres\n",
       "3652116     1677             1    37.184830\n",
       "3652117     1677             2  1631.665771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1677, 1) 37.18482971191406\n",
      "(1677, 2) 1631.665771484375\n",
      "(1677, 3) 796.68212890625\n",
      "(1677, 4) 3629.329345703125\n",
      "(1677, 5) 11.917086601257324\n"
     ]
    }
   ],
   "source": [
    "# Some pre-processing is necessary to build the parameter dictionary\n",
    "df = TblLandUsePreBmp[(TblLandUsePreBmp['baseconditionid']==baseconditionid) &\\\n",
    "                            (TblLandUsePreBmp['lrsegid'].isin(lrsegsetlist))].copy()\n",
    "\n",
    "df.drop(columns=['baseconditionid'], inplace=True)\n",
    "# and drop agency (for now!)\n",
    "df.drop(columns=['agencyid'], inplace=True)\n",
    "display(df.head(2))\n",
    "\n",
    "# Convert groups to dictionary ( with tuple->value structure ) \n",
    "grouped = df.groupby(['lrsegid', 'loadsourceid'])\n",
    "AcresDict = grouped['acres'].apply(lambda x: list(x)[0]).to_dict()\n",
    "\n",
    "# display 5 keys for illustration\n",
    "nrandkeys = list(islice(AcresDict,5))\n",
    "for k, v in zip(nrandkeys, [AcresDict[x] for x in nrandkeys]):\n",
    "    print(k, v)\n",
    "    \n",
    "T = ampl.getParameter('T')\n",
    "T.setValues(AcresDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ampl.readData(f_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve the problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error executing \"solve\" command:\n",
      "error processing constraint InGroupFactor[3,1677,1,'N']:\n",
      "\tno value for F[3,1677,1,'N']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Errors: 1; Warnings: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-348121fe8380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mampl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/jupytering/lib/python3.6/site-packages/amplpy/ampl.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadAsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupytering/lib/python3.6/site-packages/amplpy/errorhandler.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_count\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             raise RuntimeError('Errors: {}; Warnings: {}'.format(\n\u001b[0;32m---> 38\u001b[0;31m                     self.error_count, self.warning_count))\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamplexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Errors: 1; Warnings: 0"
     ]
    }
   ],
   "source": [
    "ampl.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
