{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save instance data to file?\n",
    "save2file = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseexppath = '/Users/Danny/Desktop/CATEGORIES/CAREER_MANAGEMENT/CRC_ResearchScientist_Optimization/Optimization_Tool/2_ExperimentFolder/'\n",
    "# amplappdir = os.path.join(baseexppath, 'ampl/amplide.macosx64/')\n",
    "projectpath = os.path.join(baseexppath, 'ampl/OptEfficiencySubProblem/')\n",
    "datapath = os.path.join(baseexppath, 'ampl/OptEfficiencySubProblem/data/')\n",
    "\n",
    "# # Specify model and data files\n",
    "# # f_mod = os.path.join(baseexppath, 'ampl/example/steel3.mod')\n",
    "# f_mod = os.path.join(projectpath, 'test7.mod')\n",
    "# # f_dat = os.path.join(baseexppath, 'ampl/example/steel3.dat')\n",
    "# f_dat = os.path.join(projectpath, 'test6.dat')\n",
    "\n",
    "# Data table directories\n",
    "sourcedatadir = os.path.join(baseexppath, 'OptSandbox/data/test_source/')\n",
    "metadatadir = os.path.join(baseexppath, 'OptSandbox/data/test_metadata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the data tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tables for the set definitions\n",
    "TblBmp = pd.read_csv(os.path.join(sourcedatadir, 'TblBmp.csv'))\n",
    "TblBmpGroup = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpGroup.csv'))\n",
    "TblBmpLoadSourceGroup = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpLoadSourceGroup.csv'))\n",
    "TblBmpType = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpType.csv'))\n",
    "\n",
    "TblLoadSource = pd.read_csv(os.path.join(sourcedatadir, 'TblLoadSource.csv'), skipinitialspace=True)\n",
    "TblLoadSource['loadsource'] = TblLoadSource['loadsource'].str.strip() # There is an extra space after \"Specialty Crop Low\" that needs to be removed.\n",
    "\n",
    "TblLoadSourceGroup = pd.read_csv(os.path.join(sourcedatadir, 'TblLoadSourceGroup.csv'))\n",
    "TblLoadSourceGroupLoadSource = pd.read_csv(os.path.join(sourcedatadir, 'TblLoadSourceGroupLoadSource.csv'))\n",
    "TblLandRiverSegment = pd.read_csv(os.path.join(sourcedatadir, 'TblLandRiverSegment.csv'))\n",
    "\n",
    "TblGeography = pd.read_csv(os.path.join(sourcedatadir, 'TblGeography.csv'))\n",
    "TblGeographyLrSeg = pd.read_csv(os.path.join(sourcedatadir, 'TblGeographyLrSeg.csv'))\n",
    "TblGeographyType = pd.read_csv(os.path.join(sourcedatadir, 'TblGeographyType.csv'))\n",
    "\n",
    "# Data tables for the parameter definitions\n",
    "TblCostBmpLand = pd.read_csv(os.path.join(metadatadir, 'TblCostBmpLand.csv'))\n",
    "TblBmpEfficiency = pd.read_csv(os.path.join(sourcedatadir, 'TblBmpEfficiency.csv'))\n",
    "# Target load reductions ???  (set this ourselves??)\n",
    "TblLandUsePreBmp = pd.read_csv(os.path.join(sourcedatadir, 'TblLandUsePreBmp.csv'))\n",
    "Tbl2010NoActionLoads = pd.read_csv(os.path.join(datapath, '2010NoActionLoads.csv'))\n",
    "\n",
    "# Data table generated by separate python script, the set of load source *groups* where each load source *group* contains one and only one load source\n",
    "singlelsgrpdf = pd.read_csv(os.path.join(datapath, 'single-ls_groups.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instance specifiers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$, the scenario base year (defines the available load source acres ($T$) and their base loads ($\\phi$))<br>\n",
    "$\\kappa$, the cost profile (defines the costs ($c$))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseconditionid = 29\n",
    "costprofileid=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pollutants and Land river segments**\n",
    "\n",
    "$P$, the set of pollutants $p=\\{nitrogen, phosphorous, sediment\\}$ <br>\n",
    "$L$, a set of land river segments $l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = ['N', 'P', 'S']\n",
    "df = pd.DataFrame(p_list, columns=['PLTNTS'])\n",
    "if save2file:\n",
    "    df.loc[:, ['PLTNTS']].to_csv('data_PLTNTS.tab', sep=' ', index=False)\n",
    "\n",
    "\n",
    "lrsegs_list = ['N51133RL0_6450_0000']\n",
    "lrsegids = TblLandRiverSegment[TblLandRiverSegment['landriversegment'] == lrsegs_list[0]].lrsegid.tolist()\n",
    "lrsegsetlist = list([x for x in lrsegs_list])\n",
    "lrsegsetidlist = lrsegids\n",
    "\n",
    "df = pd.DataFrame(lrsegs_list, columns=['LRSEGS'])\n",
    "if save2file:\n",
    "    df.loc[:, ['LRSEGS']].to_csv('data_LRSEGS.tab', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BMPs and their groups**\n",
    "\n",
    "$B$, a set of BMPs $b$ <br>\n",
    "$\\Gamma$, a set of BMP *groups* $\\gamma$, where $\\gamma=\\{b_{1}, b_{2}...b_{n_{\\gamma}}\\}\\subseteq B$<br>\n",
    "$\\gamma_{b}$, the BMP *group* to which BMP $b$ belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConPlan', 'AdvancedGI', 'AgStormEff', 'OSWnoFence', 'PrecRotGrazing']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[3, 13, 16, 25, 26]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('ConPlan', 3),\n",
       " ('SepticDeEnhance', 13),\n",
       " ('SepticSecEnhance', 13),\n",
       " ('SepticDeCon', 13),\n",
       " ('SepticEffEnhance', 13),\n",
       " ('SepticSecCon', 13),\n",
       " ('SepticPump', 13),\n",
       " ('AgStormEff', 16),\n",
       " ('NMCoreN', 25),\n",
       " ('NMCoreP', 26),\n",
       " ('NMRateN', 27),\n",
       " ('NMRateP', 28),\n",
       " ('NMPlaceN', 29),\n",
       " ('NMPlaceP', 30),\n",
       " ('NMTimeN', 31),\n",
       " ('NMTimeP', 32),\n",
       " ('PrecRotGrazing', 39),\n",
       " ('HorsePasMan', 39),\n",
       " ('OSWnoFence', 40),\n",
       " ('WaterContStruc', 41),\n",
       " ('AdvancedGI', 42),\n",
       " ('WetPondWetland', 42),\n",
       " ('DryPonds', 42),\n",
       " ('ExtDryPonds', 42),\n",
       " ('Infiltration', 42),\n",
       " ('InfiltWithSV', 42),\n",
       " ('Filter', 42),\n",
       " ('RR', 42),\n",
       " ('ST', 42),\n",
       " ('ImperviousDisconnection', 42),\n",
       " ('UrbFilterRR', 42),\n",
       " ('UrbFilterST', 42),\n",
       " ('BioRetUDAB', 42),\n",
       " ('BioSwale', 42),\n",
       " ('PermPavSVUDAB', 42),\n",
       " ('PermPavNoSVUDAB', 42),\n",
       " ('VegOpChanNoUDAB', 42),\n",
       " ('VegOpChanNoUDCD', 42),\n",
       " ('PermPavNoSVNoUDAB', 42),\n",
       " ('PermPavNoSVUDCD', 42),\n",
       " ('PermPavSVNoUDAB', 42),\n",
       " ('PermPavSVUDCD', 42),\n",
       " ('BioRetNoUDAB', 42),\n",
       " ('BioRetUDCD', 42),\n",
       " ('CoverCropTradRED', 43),\n",
       " ('CoverCropTradREO', 43),\n",
       " ('CoverCropTradREA', 43),\n",
       " ('CoverCropTradRND', 43),\n",
       " ('CoverCropTradRNO', 43),\n",
       " ('CoverCropTradNutBREO', 43),\n",
       " ('CoverCropTradRLD', 43),\n",
       " ('CoverCropTradRLO', 43),\n",
       " ('CoverCropTradWED', 43),\n",
       " ('CoverCropTradWEO', 43),\n",
       " ('CoverCropTradWEA', 43),\n",
       " ('CoverCropTradWND', 43),\n",
       " ('CoverCropTradWNO', 43),\n",
       " ('CoverCropTradWLD', 43),\n",
       " ('CoverCropTradWLO', 43),\n",
       " ('CoverCropTradBED', 43),\n",
       " ('CoverCropTradNutOHND', 43),\n",
       " ('CoverCropTradBEO', 43),\n",
       " ('CoverCropTradBEA', 43),\n",
       " ('CoverCropTradBND', 43),\n",
       " ('CoverCropTradBNO', 43),\n",
       " ('CoverCropTradNutOHNO', 43),\n",
       " ('CoverCropTradFED', 43),\n",
       " ('CoverCropTradFEO', 43),\n",
       " ('CoverCropComEarly', 43),\n",
       " ('CoverCropComNormal', 43),\n",
       " ('CoverCropComLate', 43),\n",
       " ('CoverCropTradNutARNO', 43),\n",
       " ('CoverCropTradNutOHED', 43),\n",
       " ('CoverCropTradNutOHEO', 43),\n",
       " ('CoverCropTradFEA', 43),\n",
       " ('CoverCropTradFPED', 43),\n",
       " ('CoverCropTradFPEO', 43),\n",
       " ('CoverCropTradFPEA', 43),\n",
       " ('CoverCropTradFPND', 43),\n",
       " ('CoverCropTradFPNO', 43),\n",
       " ('CoverCropTradLED', 43),\n",
       " ('CoverCropTradLEO', 43),\n",
       " ('CoverCropTradLEA', 43),\n",
       " ('CoverCropTradLND', 43),\n",
       " ('CoverCropTradNutBRED', 43),\n",
       " ('CoverCropTradLNO', 43),\n",
       " ('CoverCropTradLGLED', 43),\n",
       " ('CoverCropTradLGLEO', 43),\n",
       " ('CoverCropTradLGLEA', 43),\n",
       " ('CoverCropTradLGLND', 43),\n",
       " ('CoverCropTradLGLNO', 43),\n",
       " ('CoverCropTradTED', 43),\n",
       " ('CoverCropTradTEO', 43),\n",
       " ('CoverCropTradTEA', 43),\n",
       " ('CoverCropTradTND', 43),\n",
       " ('CoverCropTradTNO', 43),\n",
       " ('CoverCropTradTLD', 43),\n",
       " ('CoverCropTradTLO', 43),\n",
       " ('CoverCropTradARED', 43),\n",
       " ('CoverCropTradAREO', 43),\n",
       " ('CoverCropTradAREA', 43),\n",
       " ('CoverCropTradARND', 43),\n",
       " ('CoverCropTradARNO', 43),\n",
       " ('CoverCropTradOHED', 43),\n",
       " ('CoverCropTradOHEO', 43),\n",
       " ('CoverCropTradOHEA', 43),\n",
       " ('CoverCropTradOHND', 43),\n",
       " ('CoverCropTradOHNO', 43),\n",
       " ('CoverCropTradOKED', 43),\n",
       " ('CoverCropTradOKEO', 43),\n",
       " ('CoverCropTradOKEA', 43),\n",
       " ('CoverCropTradBRED', 43),\n",
       " ('CoverCropTradBREO', 43),\n",
       " ('CoverCropTradBREA', 43),\n",
       " ('CoverCropTradLGHED', 43),\n",
       " ('CoverCropTradLGHEO', 43),\n",
       " ('CoverCropTradLGHEA', 43),\n",
       " ('CoverCropTradLGHND', 43),\n",
       " ('CoverCropTradLGHNO', 43),\n",
       " ('CoverCropTradNutRED', 43),\n",
       " ('CoverCropTradNutREO', 43),\n",
       " ('CoverCropTradNutRND', 43),\n",
       " ('CoverCropTradNutRNO', 43),\n",
       " ('CoverCropTradNutRLD', 43),\n",
       " ('CoverCropTradNutRLO', 43),\n",
       " ('CoverCropTradNutWED', 43),\n",
       " ('CoverCropTradNutWEO', 43),\n",
       " ('CoverCropTradNutWND', 43),\n",
       " ('CoverCropTradNutWNO', 43),\n",
       " ('CoverCropTradNutWLD', 43),\n",
       " ('CoverCropTradNutWLO', 43),\n",
       " ('CoverCropTradNutBED', 43),\n",
       " ('CoverCropTradNutBEO', 43),\n",
       " ('CoverCropTradNutBND', 43),\n",
       " ('CoverCropTradNutBNO', 43),\n",
       " ('CoverCropTradNutFPED', 43),\n",
       " ('CoverCropTradNutFPEO', 43),\n",
       " ('CoverCropTradNutFPND', 43),\n",
       " ('CoverCropTradNutFPNO', 43),\n",
       " ('CoverCropTradNutTED', 43),\n",
       " ('CoverCropTradNutTEO', 43),\n",
       " ('CoverCropTradNutTND', 43),\n",
       " ('CoverCropTradNutTNO', 43),\n",
       " ('CoverCropTradNutTLD', 43),\n",
       " ('CoverCropTradNutTLO', 43),\n",
       " ('CoverCropTradNutARED', 43),\n",
       " ('CoverCropTradNutAREO', 43),\n",
       " ('CoverCropTradNutARND', 43),\n",
       " ('UrbanNMPlan', 44),\n",
       " ('UrbanNMPlanHR', 44),\n",
       " ('UrbanNMPlanLR', 44),\n",
       " ('UrbanNMMDCA', 44),\n",
       " ('UrbanNMMDDIY', 44),\n",
       " ('ForHarvestBMP', 45),\n",
       " ('SCP1', 46),\n",
       " ('SCP2', 46),\n",
       " ('SCP3', 46),\n",
       " ('SCP4', 46),\n",
       " ('SCP5', 46),\n",
       " ('SCP6', 46),\n",
       " ('SCP7', 46),\n",
       " ('SCP8', 46),\n",
       " ('SCP9', 46),\n",
       " ('SCP10', 46),\n",
       " ('SCP11', 46),\n",
       " ('FTW1', 47),\n",
       " ('FTW2', 47),\n",
       " ('FTW3', 47),\n",
       " ('FTW4', 47),\n",
       " ('FTW5', 47),\n",
       " ('BarnRunoffCont', 48),\n",
       " ('LoafLot', 48),\n",
       " ('DitchFilter', 97),\n",
       " ('Injection', 98),\n",
       " ('IncorpLowEarly', 98),\n",
       " ('IncorpHighEarly', 98),\n",
       " ('IncorpLowLate', 98),\n",
       " ('IncorpHighLate', 98),\n",
       " ('CropIrrMgmt', 105),\n",
       " ('LowResTill', 112),\n",
       " ('ConserveTill', 112),\n",
       " ('HRTill', 112),\n",
       " ('CaptureReuse', 114),\n",
       " ('EandS1', 115),\n",
       " ('EandS2', 115),\n",
       " ('EandS3', 115)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Restrict BMPs to include:\n",
    "#  - Only include b if it's an 'efficiency' BMP\n",
    "#  - Only include b if it has a load source group on which it can be implemented\n",
    "efftypeid = TblBmpType[TblBmpType['bmptype']=='Efficiency']['bmptypeid'].tolist()[0]\n",
    "bmpsdf = TblBmp[TblBmp['bmptypeid']==(efftypeid)]\n",
    "bmpsdf = bmpsdf[bmpsdf['bmpid'].isin(TblBmpLoadSourceGroup.bmpid.tolist())]\n",
    "\n",
    "bmps = ampl.getSet('BMPS')\n",
    "# display(bmpsdf.head(2))\n",
    "bmps.setValues(bmpsdf.bmpshortname.tolist())\n",
    "# bmpsetlist = bmpsdf.bmpid.tolist()\n",
    "bmpsetlist = list([x for x in bmps.getValues().toPandas().index])\n",
    "bmpsetidlist = bmpsdf.bmpid.tolist()\n",
    "#print(bmps.getValues())\n",
    "display(bmpsetlist[:5])\n",
    "df = pd.DataFrame(bmpsetlist, columns=['BMPS'])\n",
    "df.loc[:, ['BMPS']].to_csv('data_BMPS.tab',sep=' ',index=False)\n",
    "\n",
    "bmpgrps = ampl.getSet('BMPGRPS')\n",
    "# bmpgrpdf = TblBmpGroup[TblBmpGroup['ruleset']=='spbmpruleset_efficiencybmps']\n",
    "# TblBmpGroup[TblBmpGroup['ruleset']=='spbmpruleset_efficiencybmps']\n",
    "bmpgrpsdf = TblBmpGroup.loc[:, ['bmpgroupid', 'bmpgroupname']].merge(bmpsdf[['bmpgroupid','bmpshortname']])\n",
    "# display(bmpgrpsdf.head(5))\n",
    "bmpgrps.setValues(set(bmpgrpsdf.bmpgroupid))\n",
    "bmpgrpsetlist = list([int(x) for x in bmpgrps.getValues().toPandas().index])\n",
    "#print(bmpgrps.getValues())\n",
    "display(bmpgrpsetlist[:5])\n",
    "df = pd.DataFrame(bmpgrpsetlist, columns=['BMPGRPS'])\n",
    "df.loc[:, ['BMPGRPS']].to_csv('data_BMPGRPS.tab',sep=' ',index=False)\n",
    "\n",
    "bmpgrping = ampl.getSet('BMPGRPING')\n",
    "grpingdf = amplpy.DataFrame(('BMPS', 'BMPGRPS'))\n",
    "# grpingdf.setValues(list(zip(bmpsdf.bmpid.tolist(),\n",
    "#                               bmpsdf.bmpgroupid.tolist())))\n",
    "# bmpgrping.setData(grpingdf, 'BMPGRPING')\n",
    "bmpgrpingsetlist = list(zip(bmpgrpsdf.bmpshortname.tolist(),\n",
    "                             bmpgrpsdf.bmpgroupid.tolist()))\n",
    "bmpgrping.setValues(bmpgrpingsetlist)\n",
    "display(bmpgrpingsetlist)\n",
    "# print(bmpgrping.getValues())\n",
    "\n",
    "# tempsrs = pd.Series(bmpgrpingsetlist)\n",
    "# df = pd.DataFrame(tempsrs, columns=['BMPGRPING'])\n",
    "bmpgrpsdf.loc[:, ['bmpshortname', 'bmpgroupid']].to_csv('data_BMPGRPING.tab',\n",
    "                                                        sep=' ',\n",
    "                                                        index=False,\n",
    "                                                        header=['BMPS', 'BMPGRPS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Sources and their groups**\n",
    "\n",
    "$\\Lambda$, the set of load sources $\\lambda$ <br>\n",
    "$\\Psi$, the set of all load source *groups* $\\psi$, where $\\psi=\\{\\lambda_{1}, \\lambda_{2}...\\lambda_{m_{\\psi}}\\}\\subseteq\\Lambda$ <br>\n",
    "$\\Psi^{*}$, the set of load source *groups* where each load source *group* contains one and only one load source ($\\Psi^{*}\\subset\\Psi\\quad\\mid\\quad\\left\\vert\\psi^{*}\\right\\vert=1 \\quad\\forall \\psi^{*}\\in\\Psi^{*} $) <br>\n",
    "$\\psi_{\\lambda}^{*}$, the load source *group* containing only the load source $\\lambda$ <br>\n",
    "\n",
    "*Furthermore*, limit the load sources set to only include those that have base loading rates defined in the No Action data, and only those that have an acreage defined in TblLandUsePreBmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadsrcs = ampl.getSet('LOADSRCS')\n",
    "# limit the load sources set to only include those that have \n",
    "#  base loading rates defined in the No Action data, \n",
    "#  and only those that have an acreage defined in TblLandUsePreBmp\n",
    "landusedf = TblLandUsePreBmp[(TblLandUsePreBmp['baseconditionid']==baseconditionid) &\\\n",
    "                      (TblLandUsePreBmp['lrsegid'].isin(lrsegsetidlist))].copy()\n",
    "landusedf = singlelsgrpdf[singlelsgrpdf['loadsourceid'].isin(landusedf['loadsourceid'])]\n",
    "display(landusedf.head(1))\n",
    "\n",
    "loadsrcs.setValues(landusedf.loadsourceshortname.tolist())\n",
    "loadsrcsetlist = list([x for x in loadsrcs.getValues().toPandas().index])\n",
    "loadsrcsetidlist = landusedf.loadsourceid.tolist()\n",
    "#print(loadsrcs.getValues())\n",
    "#display(loadsrcsetlist)\n",
    "df = pd.DataFrame(loadsrcsetlist, columns=['LOADSRCS'])\n",
    "df.loc[:, ['LOADSRCS']].to_csv('data_LOADSRCS.tab',sep=' ',index=False)\n",
    "\n",
    "\n",
    "# loadsrcgrps = ampl.getSet('LOADSRCGRPS')\n",
    "# loadsrcgrps.setValues(landusedf.loadsourcegroup.tolist())\n",
    "# loadsrcgrpsetlist = list([x for x in loadsrcgrps.getValues().toPandas().index])\n",
    "# # print(loadsrcgrps.getValues())\n",
    "\n",
    "# loadsrcgrps = ampl.getSet('SINGLELSGRPS')\n",
    "# loadsrcgrps.setValues(singlelslandusedf.loadsourcegroup.tolist())\n",
    "# loadsrcgrpsetlist = list([x for x in loadsrcgrps.getValues().toPandas().index])\n",
    "# # print(loadsrcgrps.getValues())\n",
    "\n",
    "# singlesrcgrping = ampl.getSet('SINGLESRCGRPING')\n",
    "# singlesrcgrping.setValues(list(zip(singlelsgrpdf.loadsourceshortname.tolist(),\n",
    "#                                    singlelsgrpdf.loadsourcegroup.tolist())))\n",
    "\n",
    "# --- Get the correspondences between BMPS, BMPGRPS, LOADSRCS, and LOADSRCGRPS ---\n",
    "srcbmpsubtbl = TblBmpLoadSourceGroup.loc[:,:].merge(singlelsgrpdf, on='loadsourcegroupid')\n",
    "# restrict membership to those bmps and loadsources within the sets BMPS and LOADSRCS\n",
    "srcbmpsubtbl = srcbmpsubtbl[srcbmpsubtbl['bmpid'].isin(bmpsetidlist)]\n",
    "srcbmpsubtbl = srcbmpsubtbl[srcbmpsubtbl['loadsourceid'].isin(loadsrcsetidlist)]\n",
    "# Add bmpgroup ids\n",
    "srcbmpsubtbl = TblBmp.loc[:,['bmpid', 'bmpgroupid']].merge(srcbmpsubtbl)\n",
    "\n",
    "# --- Only include (b, lambda) pairs in BMPSRCLINKS if its b has an efficiency value ---\n",
    "# --- for that lambda (and its associated loadsourcegroup) in TblBmpEfficiency ---\n",
    "# restrict membership to the land river segments in LRSEGS\n",
    "effsubtable = TblBmpEfficiency[TblBmpEfficiency['lrsegid'].isin(lrsegsetidlist)]\n",
    "\n",
    "# retain only the (b, lambda) pairs in the srcbmpsubtbl with effectiveness values\n",
    "bmpsrclinkssubtbl = srcbmpsubtbl.loc[:,:].merge(effsubtable.loc[:,['bmpid','loadsourceid']], on=['bmpid', 'loadsourceid'])\n",
    "display('after filtering srcbmpsubtbl by effsubtable')\n",
    "display(bmpsrclinkssubtbl.head(2))\n",
    "\n",
    "# Add BMP, bmpgroup, and loadsource names\n",
    "bmpsrclinkssubtbl = TblBmp.loc[:,['bmpid', 'bmpshortname']].merge(bmpsrclinkssubtbl)\n",
    "bmpsrclinkssubtbl = TblLoadSource.loc[:,['loadsourceid', 'loadsourceshortname']].merge(bmpsrclinkssubtbl)\n",
    "bmpsrclinkssubtbl = TblBmpGroup.loc[:,['bmpgroupid', 'bmpgroupname']].merge(bmpsrclinkssubtbl)\n",
    "bmpsrclinkssubtbl.to_csv('tempBMPSRCLINKS.csv')\n",
    "display('after adding names to table')\n",
    "display(bmpsrclinkssubtbl.head(2))\n",
    "\n",
    "# retain only bmp groups for the BMPGRPSRCLINKS set\n",
    "bmpsrcgrplinkssubtbl = bmpsrclinkssubtbl.drop_duplicates(['bmpgroupname', 'loadsourceshortname'])\n",
    "bmpsrcgrplinkssubtbl.to_csv('tempBMPGRPSRCLINKS.csv')\n",
    "display('after retaining only bmp groups')\n",
    "display(bmpsrcgrplinkssubtbl.head(2))\n",
    "\n",
    "\n",
    "bmpsrclinks = ampl.getSet('BMPSRCLINKS')\n",
    "bmpsrclinkslist = list(zip(bmpsrclinkssubtbl.bmpshortname.tolist(),\n",
    "                               bmpsrclinkssubtbl.loadsourceshortname.tolist()))\n",
    "bmpsrclinks.setValues(bmpsrclinkslist)\n",
    "# print(loadsrcgrping.getValues())\n",
    "\n",
    "# tempsrs = pd.Series(bmpsrclinkslist)\n",
    "# df = pd.DataFrame(tempsrs, columns=['BMPSRCLINKS'])\n",
    "bmpsrcgrplinkssubtbl.loc[:, ['bmpshortname', 'loadsourceshortname']].to_csv('data_BMPSRCLINKS.tab',\n",
    "                            sep=' ',\n",
    "                            index=False,\n",
    "                            header=['BMPS', 'LOADSRCS'])\n",
    "\n",
    "bmpgrpsrclinks = ampl.getSet('BMPGRPSRCLINKS')\n",
    "# groupedcnt = srcbmpsubtbl.groupby(by=['bmpgroupname', 'loadsourceshortname']).agg('count')\n",
    "# display(groupedcnt)\n",
    "bmpgrpsrclinkslist = list(zip(bmpsrcgrplinkssubtbl.bmpgroupid.tolist(),\n",
    "                                  bmpsrcgrplinkssubtbl.loadsourceshortname.tolist()))\n",
    "bmpgrpsrclinks.setValues(bmpgrpsrclinkslist)\n",
    "print(bmpgrpsrclinks.getValues())\n",
    "\n",
    "# tempsrs = pd.Series(bmpgrpsrclinkslist)\n",
    "# df = pd.DataFrame(tempsrs, columns=['BMPGRPSRCLINKS'])\n",
    "bmpsrcgrplinkssubtbl.loc[:, ['bmpgroupid', 'loadsourceshortname']].to_csv('data_BMPGRPSRCLINKS.tab',\n",
    "                            sep=' ',\n",
    "                            index=False,\n",
    "                            header=['BMPGRPS', 'LOADSRCS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c_{b}^{\\kappa}$, the cost per acre of BMP $b$ (for cost profile $\\kappa$) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ampl.getParameter('c')\n",
    "\n",
    "df = TblCostBmpLand[TblCostBmpLand['costprofileid']==costprofileid]\n",
    "# Retain only those costs pertaining to bmps in our set\n",
    "display(bmpsetlist[:5])\n",
    "df = df.merge(TblBmp[['bmpshortname','bmpid']])\n",
    "df = df[df['bmpshortname'].isin(bmpsetlist)]\n",
    "display(df.head(5))\n",
    "\n",
    "c.setValues(dict(zip(df.bmpshortname, df.totalannualizedcostperunit)))\n",
    "df.loc[:, ['bmpshortname', 'totalannualizedcostperunit']].to_csv('data_c.tab',\n",
    "                                                                 sep=' ',\n",
    "                                                                 index=False,\n",
    "                                                                header=['BMPS', 'c'])\n",
    "#print(c.getValues())\n",
    "# asdlhjasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E_{b,p,l,\\lambda}$, the effectiveness per acre of BMP $b$ on reducing pollutant $p$, in land-river segment $l$ and load source $\\lambda$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing is necessary to build the parameter dictionary\n",
    "display(bmpsetidlist[:5])\n",
    "effsubtable = TblBmpEfficiency[TblBmpEfficiency['lrsegid'].isin(lrsegsetidlist)]\n",
    "# make the pollutant names into an index instead of separate columns\n",
    "listofdataframes = []\n",
    "pltntdict = {'tn': 'N', 'tp': 'P', 'sed': 'S'}\n",
    "for ps in ['tn', 'tp', 'sed']:\n",
    "    bmpeff = effsubtable.loc[:, ['bmpid', 'lrsegid', 'loadsourceid', ps]]\n",
    "    bmpeff['pltnt'] = pltntdict[ps]\n",
    "    bmpeff.rename(columns={ps: 'effvalue'}, inplace=True)\n",
    "    listofdataframes.append(bmpeff)\n",
    "df = pd.concat(listofdataframes)\n",
    "\n",
    "# Retain only those effectivenesses pertaining to loadsources in our set\n",
    "df = df[df['loadsourceid'].isin(loadsrcsetidlist)]\n",
    "# Retain only those costs pertaining to bmps in our set\n",
    "df = df[df['bmpid'].isin(bmpsetidlist)]\n",
    "\n",
    "display(df.head(5))\n",
    "\n",
    "df = TblBmp.loc[:,['bmpid','bmpshortname']].merge(df)\n",
    "df = TblLandRiverSegment.loc[:,['lrsegid','landriversegment']].merge(df)\n",
    "df = TblLoadSource.loc[:,['loadsourceid','loadsourceshortname']].merge(df)\n",
    "display(df.head(5))\n",
    "display(df[df['bmpid']==48])\n",
    "\n",
    "# Convert groups to dictionary ( with tuple->value structure ) \n",
    "grouped = df.groupby(['bmpshortname', 'pltnt', 'landriversegment', 'loadsourceshortname'])\n",
    "Edict = grouped['effvalue'].apply(lambda x: list(x)[0]).to_dict()\n",
    "\n",
    "# # display 5 keys for illustration\n",
    "# nrandkeys = list(islice(Edict,5))\n",
    "# for k, v in zip(nrandkeys, [Edict[x] for x in nrandkeys]):\n",
    "#     print(k, v)\n",
    "\n",
    "E = ampl.getParameter('E')\n",
    "E.setValues(Edict)\n",
    "\n",
    "df.loc[:, ['bmpshortname', 'pltnt',\n",
    "           'landriversegment',\n",
    "           'loadsourceshortname','effvalue']].to_csv('data_E.tab',\n",
    "                                                     sep=' ',\n",
    "                                                     index=False,\n",
    "                                                    header=['BMPS',\n",
    "                                                            'PLTNTS',\n",
    "                                                            'LRSEGS',\n",
    "                                                            'LOADSRCS',\n",
    "                                                            'E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tau_{l,p}$, the target percent load reduction per pollutant per land river segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = ampl.getParameter('tau')\n",
    "\n",
    "Taudict = {}\n",
    "for l in lrsegsetlist:\n",
    "    Taudict[(l, 'N')] = 7\n",
    "    Taudict[(l, 'P')] = 7\n",
    "    Taudict[(l, 'S')] = 7\n",
    "display(Taudict)\n",
    "\n",
    "tau.setValues(Taudict)\n",
    "\n",
    "df = pd.DataFrame(list(Taudict.items()), columns=['LRSEGS', 'tau'])\n",
    "display(df)\n",
    "df[['LRSEGS', 'PLTNTS']] = df['LRSEGS'].apply(pd.Series)\n",
    "df = df[['LRSEGS', 'PLTNTS', 'tau']]\n",
    "display(df)\n",
    "df.to_csv('data_tau.tab', sep=' ',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi_{l,\\lambda,p}^{y}$, the base nutrient load per pollutant per load source per land river segment (for year $y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing is necessary to build the parameter dictionary\n",
    "\n",
    "# Unfortunately, the NoActionLoads table is from the website so doesn't have id numbers.  Let's translate this table to id numbers...\n",
    "\n",
    "# Let's make sure the columns are all lowercase\n",
    "Tbl2010NoActionLoads.columns = map(str.lower, Tbl2010NoActionLoads.columns)\n",
    "\n",
    "# First, let's translate our lrseg list to the fullnames so we can subset it before translating.\n",
    "gtypeid = TblGeographyType[TblGeographyType['geographytypefullname']=='Land River Segment indicating if in or out of CBWS'].geographytypeid.tolist()[0]\n",
    "geolrsegsubtbl = TblGeographyLrSeg.loc[TblGeographyLrSeg['lrsegid'].isin(lrsegsetidlist)]\n",
    "geosubtbl = geolrsegsubtbl.merge(TblGeography, on='geographyid', how='inner')\n",
    "lrsegfullnames = geosubtbl[geosubtbl['geographytypeid']==gtypeid].geographyfullname.tolist()\n",
    "\n",
    "loadssubtbl = Tbl2010NoActionLoads[Tbl2010NoActionLoads['geography'].isin(lrsegfullnames)]\n",
    "\n",
    "# Go from load source table with geographyfullname to geographyid\n",
    "includecols = ['geography', 'loadsource', '2010 no action_nloadeos', '2010 no action_ploadeos', '2010 no action_sloadeos']\n",
    "loadssubtbl = loadssubtbl.loc[:, includecols].merge(TblGeography, how='inner',\n",
    "                                                    left_on='geography',\n",
    "                                                    right_on='geographyfullname')\n",
    "loadssubtbl.drop(columns=['geographyname',\n",
    "                          'geographyfullname',\n",
    "                          'geography',\n",
    "                          'geographytypeid'], inplace=True)\n",
    "\n",
    "# Go from load source table with geographyid to lrsegid\n",
    "includecols = ['geographyid', 'lrsegid']\n",
    "loadssubtbl = TblGeographyLrSeg.loc[:,includecols].merge(loadssubtbl, how='inner',\n",
    "                                                         on='geographyid')\n",
    "loadssubtbl.drop(columns=['geographyid'], inplace=True)\n",
    "\n",
    "# Go from LoadSource to loadsourceid\n",
    "includecols = ['loadsourceid', 'loadsource']\n",
    "loadssubtbl = TblLoadSource.loc[:,includecols].merge(loadssubtbl, how='inner',\n",
    "                                                     on='loadsource')\n",
    "loadssubtbl.drop(columns=['loadsource'], inplace=True)\n",
    "display(loadssubtbl.head(2))\n",
    "\n",
    "# only retain loadsources that are represented by a single-ls loadsource group.\n",
    "loadssubtbl = loadssubtbl[loadssubtbl['loadsourceid'].isin(loadsrcsetidlist)]\n",
    "\n",
    "# make the pollutant names into an index instead of separate columns\n",
    "listofdataframes = []\n",
    "pcolnames = ['2010 no action_nloadeos', '2010 no action_ploadeos', '2010 no action_sloadeos']\n",
    "pltntdict = {pcolnames[0]: 'N',\n",
    "             pcolnames[1]: 'P',\n",
    "             pcolnames[2]: 'S'}\n",
    "for ps in [pcolnames[0], pcolnames[1], pcolnames[2]]:\n",
    "    llload = loadssubtbl.loc[:, ['lrsegid', 'loadsourceid', ps]]\n",
    "    llload['pltnt'] = pltntdict[ps]\n",
    "    llload.rename(columns={ps: 'loadratelbsperyear'}, inplace=True)\n",
    "    listofdataframes.append(llload)\n",
    "df = pd.concat(listofdataframes)\n",
    "display(df.head(5))\n",
    "\n",
    "df = TblLandRiverSegment.loc[:,['lrsegid','landriversegment']].merge(df)\n",
    "df = TblLoadSource.loc[:,['loadsourceid','loadsourceshortname']].merge(df)\n",
    "display(df.head(5))\n",
    "\n",
    "# Convert groups to dictionary ( with tuple->value structure ) \n",
    "grouped = df.groupby(['landriversegment', 'loadsourceshortname', 'pltnt'])\n",
    "LoadDict = grouped['loadratelbsperyear'].apply(lambda x: list(x)[0]).to_dict()\n",
    "\n",
    "# display 5 keys for illustration\n",
    "nrandkeys = list(islice(LoadDict,5))\n",
    "for k, v in zip(nrandkeys, [LoadDict[x] for x in nrandkeys]):\n",
    "    print(k, v)\n",
    "\n",
    "phi = ampl.getParameter('phi')\n",
    "phi.setValues(LoadDict)\n",
    "\n",
    "df.loc[:, ['landriversegment', 'loadsourceshortname',\n",
    "           'pltnt', 'loadratelbsperyear']].to_csv('data_phi.tab',\n",
    "                                                  sep=' ',\n",
    "                                                  index=False,\n",
    "                                                  header=['LRSEGS',\n",
    "                                                          'LOADSRCS',\n",
    "                                                          'PLTNTS',\n",
    "                                                          'phi'])\n",
    "\n",
    "# lrsegfullnames.loc[:,['geographyfullname'].merge(Tbl2010NoActionLoads, left_on=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{l,\\lambda}^{y}$, the total acres available for land-river segment $l$ and load source $\\lambda$ (for year $y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing is necessary to build the parameter dictionary\n",
    "df = TblLandUsePreBmp[(TblLandUsePreBmp['baseconditionid']==baseconditionid) &\\\n",
    "                            (TblLandUsePreBmp['lrsegid'].isin(lrsegsetidlist))].copy()\n",
    "\n",
    "df.drop(columns=['baseconditionid'], inplace=True)\n",
    "# and drop agency (for now!)\n",
    "df.drop(columns=['agencyid'], inplace=True)\n",
    "display(df.head(2))\n",
    "\n",
    "df = TblLandRiverSegment.loc[:,['lrsegid','landriversegment']].merge(df)\n",
    "df = TblLoadSource.loc[:,['loadsourceid','loadsourceshortname']].merge(df)\n",
    "display(df.head(2))\n",
    "\n",
    "# Convert groups to dictionary ( with tuple->value structure ) \n",
    "grouped = df.groupby(['landriversegment', 'loadsourceshortname'])\n",
    "AcresDict = grouped['acres'].apply(lambda x: list(x)[0]).to_dict()\n",
    "\n",
    "# display 5 keys for illustration\n",
    "nrandkeys = list(islice(AcresDict,5))\n",
    "for k, v in zip(nrandkeys, [AcresDict[x] for x in nrandkeys]):\n",
    "    print(k, v)\n",
    "\n",
    "T = ampl.getParameter('T')\n",
    "T.setValues(AcresDict)\n",
    "\n",
    "df.loc[:, ['landriversegment', 'loadsourceshortname',\n",
    "           'acres']].to_csv('data_T.tab',\n",
    "                            sep=' ',\n",
    "                            index=False,\n",
    "                            header=['LRSEGS', 'LOADSRCS', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ampl.readData(f_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bmpgrps.getValues())\n",
    "# print(bmpgrping.contains((10,16)))\n",
    "# print(bmpgrping.getValues())\n",
    "# print(lrsegs.getValues())\n",
    "print(loadsrcs.getValues())\n",
    "print(bmps.getValues())\n",
    "# print(pltnts.getValues())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve the problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(TblBmpGroup[TblBmpGroup['bmpgroupname']=='Septic Denitrification and Pumping'])\n",
    "# display(TblBmpGroup[TblBmpGroup['bmpgroupname']=='Urban Nutrient Management'])\n",
    "# display(TblBmpGroup[TblBmpGroup['bmpgroupname']=='Ag Stormwater Management'])\n",
    "display(TblBmp[TblBmp['bmpshortname']=='CoverCropTradRED'])\n",
    "# display(TblBmp[TblBmp['bmpgroupid']==16])\n",
    "\n",
    "display(TblBmp[TblBmp['bmpshortname']=='CoverCropTradRED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl.exportData('test6.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# askdjhgasdkjhg # fix the errors\n",
    "ampl.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalcost = ampl.getObjective('Total_Cost')\n",
    "print(\"Objective is:\", totalcost.get().value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minret = ampl.getVariable('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = minret.getValues()\n",
    "df = df.toPandas()\n",
    "\n",
    "nonzerodf = df.iloc[df['x.val'].nonzero()[0]]\n",
    "display(nonzerodf.shape)\n",
    "display(nonzerodf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadssubtbl = pd.DataFrame([x[2] for x in nonzerodf.index], columns=['loadsourceshortname'])\n",
    "# print(str(loadssubtbl))\n",
    "\n",
    "# # Go from loadsourceshortname to LoadSource\n",
    "# includecols = ['loadsourceshortname', 'loadsource']\n",
    "# loadssubtbl = loadssubtbl.merge(TblLoadSource.loc[:,includecols], how='left', on='loadsourceshortname')\n",
    "# loadssubtbl.drop(columns=['loadsourceshortname'], inplace=True)\n",
    "# display(loadssubtbl.head(10))\n",
    "# loadssubtbl.loadsource\n",
    "\n",
    "bmpssubtbl = pd.DataFrame([x[0] for x in nonzerodf.index], columns=['bmpshortname'])\n",
    "print(str(bmpssubtbl))\n",
    "\n",
    "# Go from loadsourceshortname to LoadSource\n",
    "includecols = ['bmpshortname', 'bmpid']\n",
    "bmpssubtbl = bmpssubtbl.merge(TblBmp.loc[:,includecols], how='left', on='bmpshortname')\n",
    "bmpssubtbl.drop(columns=['bmpshortname'], inplace=True)\n",
    "#display(bmpssubtbl.head(10))\n",
    "bmpssubtbl.bmpid\n",
    "\n",
    "costsubtbl = TblCostBmpLand[TblCostBmpLand['costprofileid']==costprofileid]\n",
    "# Retain only those costs pertaining to bmps in our set\n",
    "includecols = ['totalannualizedcostperunit', 'bmpid']\n",
    "costsubtbl = bmpssubtbl.merge(costsubtbl.loc[:,includecols])\n",
    "display(costsubtbl.head(5))\n",
    "print(costprofileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(costsubtbl.loc[:,'totalannualizedcostperunit'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(nonzerodf['x.val'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ldsrcstrs = [str([x[0], x[2]]) for x in nonzerodf.index]  # we don't need lrseg name, which is x[1], for now.\n",
    "#plt.barh(y=ldsrcstrs, width=nonzerodf['x.val'])\n",
    "#xlbl=plt.xlabel('acres')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "rects = plt.barh(y=ldsrcstrs, width=nonzerodf['x.val'])\n",
    "ax = plt.gca()\n",
    "\n",
    "totalinstancecost = np.multiply(costsubtbl.loc[:,'totalannualizedcostperunit'].values,\n",
    "                                nonzerodf['x.val'].values)\n",
    "coststrs = [str(x) for x in zip(list(costsubtbl['totalannualizedcostperunit']),\n",
    "                                    list(totalinstancecost)\n",
    "                                   )\n",
    "          ]\n",
    "\n",
    "for rect, label in zip(rects, coststrs):\n",
    "    width = rect.get_width()\n",
    "    plt.text(width + 0.1, rect.get_y() + rect.get_height() / 2, label,\n",
    "            ha='left', va='center')\n",
    "\n",
    "objstr = ''.join(['Objective is: ', str(totalcost.get().value())])\n",
    "labelstr = 'labels are (cost per unit, total bmp instance cost)'\n",
    "plt.title('\\n'.join([objstr, labelstr]))\n",
    "\n",
    "ax.set_position([0.3,0.1,0.5,0.8])\n",
    "#plt.tight_layout()\n",
    "\n",
    "\n",
    "#plt.savefig(os.path.join(projectpath,''.join(['output/tau19N19P19S_minos_', datetime.now().strftime('%Y-%m-%d_%H%M%S'),'.png'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conname = ampl.getData(\"_conname\").toPandas()\n",
    "df_con = ampl.getData(\"_con\").toPandas()\n",
    "\n",
    "df_cons = pd.concat([df_conname, df_con], axis=1)\n",
    "display(df_cons.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)  # allow display of dataframe cells with long widths, without truncation\n",
    "nonzerodf_cons = df_cons.loc[df_cons['_con'] != 0]\n",
    "display(nonzerodf_cons.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_varname = ampl.getData(\"_varname\").toPandas()\n",
    "df_vardual = ampl.getData(\"_var.dual\").toPandas()\n",
    "df_varrc = ampl.getData(\"_var.rc\").toPandas()\n",
    "\n",
    "df_vars = pd.concat([df_varname, df_vardual, df_varrc], axis=1)\n",
    "display(df_vars.head(5))\n",
    "\n",
    "nonzerodf_vars = df_vars.loc[(df_vars['_var.dual'] != 0) | (df_vars['_var.rc'] != 0)]\n",
    "display(nonzerodf_vars.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nvars = ampl.getData(\"_nvars\").toPandas()\n",
    "display(df_nvars)\n",
    "df_nvars = ampl.getData(\"_varname\").toPandas()\n",
    "display(df_nvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = ampl.setOption('solver', 'gjh')\n",
    "value = ampl.getOption('solver')\n",
    "display(value)\n",
    "ampl.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
