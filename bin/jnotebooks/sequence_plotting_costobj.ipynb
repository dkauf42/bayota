{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # allow this notebook to find equal-level directories\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "%pylab inline\n",
    "# from importing_modules import *\n",
    "# pyomo.environ as oe, seaborn as sns, plotly.plotly as py, plotly.graph_objs as go\n",
    "# from util.gjh_wrapper import gjh_solve, make_df, from vis import acres_bars, zL_bars\n",
    "\n",
    "_project_root = '/Users/Danny/Desktop/CATEGORIES/CAREER_MANAGEMENT/' \\\n",
    "        'CRC_ResearchScientist_Optimization/Optimization_Tool/' \\\n",
    "        '2_ExperimentFolder/bayota/'\n",
    "_package_root = '/Users/Danny/Desktop/CATEGORIES/CAREER_MANAGEMENT/' \\\n",
    "        'CRC_ResearchScientist_Optimization/Optimization_Tool/' \\\n",
    "        '2_ExperimentFolder/bayota/efficiencysubproblem/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Solution Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = 'output/20180904-county-NorthumberlandVA_costobj-sequence/costobj_tausequence_alldfs_ipopt_2018-09-04_141616.csv'\n",
    "filename = 'output/output_study_costmin_countytausequence8_tau9_2018-10-03_113849.csv'\n",
    "df = pd.read_csv(os.path.join(_package_root, filename))\n",
    "# display(df.head(2))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby(by=['bmpshortname', 'loadsource'])\n",
    "len(grouped)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot table for acres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136        ('HRTill', 'N51133RL0_6450_0000', 'soy', 0.0)\n",
       "137    ('UrbanNMPlanHR', 'N51133RL0_6450_0000', 'nch'...\n",
       "138    ('UrbanNMPlanHR', 'N51133RL0_6450_0000', 'ntg'...\n",
       "139        ('HRTill', 'N51133RL0_6450_0000', 'dbl', 0.0)\n",
       "140        ('HRTill', 'N51133RL0_6450_0000', 'gom', 0.0)\n",
       "Name: x, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['x'].head(5)\n",
    "df['x'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tau'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3064\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3065\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tau'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04de8059e590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_piv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acres'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_piv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# make tau into a regular column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_piv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'range'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_piv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_piv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'objective'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_piv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolution_objectives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# solution_objectives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# df_piv.head(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   5192\u001b[0m         \"\"\"\n\u001b[1;32m   5193\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5196\u001b[0m     _shared_docs['pivot_table'] = \"\"\"\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OptSubProblem/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3064\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tau'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df_piv = df.pivot(index='tau', columns='x', values='acres')\n",
    "df_piv.reset_index(level=['tau'], inplace=True)  # make tau into a regular column\n",
    "df_piv['range']=df_piv.drop('tau', axis=1).apply(lambda x : list((0, int(math.ceil(np.nanmax(x))+1))), 1)\n",
    "df_piv['objective'] = df_piv['tau'].map(dict(zip(df.tau,df.solution_objectives)))  # solution_objectives\n",
    "# df_piv.head(2)\n",
    "\n",
    "# df_piv = df.pivot(index='startpointiterate', columns='x', values='acres')\n",
    "# display(df_piv.head(2))\n",
    "# df_piv.reset_index(level=['startpointiterate'], inplace=True)  # make tau into a regular column\n",
    "# display(df_piv.head(2))\n",
    "# df_piv['range']=df_piv.drop('startpointiterate', axis=1).apply(lambda x : list((0, int(math.ceil(np.nanmax(x))+1))), 1)\n",
    "# display(df_piv.head(2))\n",
    "# df_piv['objective'] = df_piv['startpointiterate'].map(dict(zip(df.startpointiterate,df.solution_objectives)))  # solution_objectives\n",
    "# display(df_piv.head(2))\n",
    "\n",
    "display(df_piv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_piv['objective'].isnan()\n",
    "# df['tau'].isnull().values.any()\n",
    "# print(dict(zip(df.tau,df.solution_objectives)))\n",
    "\n",
    "display(df_piv.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot table for gradient (g), if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'g' in df.columns:\n",
    "    df_g_piv = df.pivot(index='tau', columns='x', values='g')\n",
    "    df_g_piv.reset_index(level=['tau'], inplace=True)  # make tau into a regular column\n",
    "    df_g_piv['range']=df_g_piv.drop('tau', axis=1).apply(lambda x : list((0, int(math.ceil(np.nanmax(x))+1))), 1)\n",
    "    df_g_piv['objective'] = df_g_piv['tau'].map(dict(zip(df.tau,df.solution_objectives)))  # solution_objectives\n",
    "    # df_g_piv.head(2)\n",
    "else:\n",
    "    print(\"skipping because no column 'g'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['bmpshortname','landriversegment','totalinstancecost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['landriversegment', 'tau'])['totalinstancecost'].sum()\n",
    "display(grouped.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficiencysubproblem.src.vis.sequence_plot import plotly_costobj\n",
    "from efficiencysubproblem.src.vis.acres_heatmap import heatmap_costobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plotly_costobj(df=df_piv, xname='startpointiterate')\n",
    "fig = plotly_costobj(df=df_piv, xname='tau')\n",
    "py.iplot(fig, filename='styled-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get costs of tau sequence for each lrseg\n",
    "grped = df.groupby(['landriversegment', 'tau'])['totalinstancecost'].sum()\n",
    "\n",
    "xname = 'tau'\n",
    "title='Minimal Total Cost vs. Load Constraint'\n",
    "xlabel='Load Reduction (%) Lower Bound Constraint'\n",
    "ylabel='Minimal Total Cost ($)'\n",
    "\n",
    "#Create a trace\n",
    "county_trace = go.Scatter(x=df_piv[xname],\n",
    "                   y=df_piv['objective'],\n",
    "                          name='County'\n",
    "                   )\n",
    "\n",
    "lrseglist = list(set(df.landriversegment))\n",
    "traces = [county_trace]\n",
    "for l in lrseglist:\n",
    "#     print(l)\n",
    "#     display(grped.loc[l].tolist())\n",
    "    \n",
    "    traces.append(go.Scatter(x=grped.index.get_level_values('tau'),\n",
    "                             y=grped.loc[l].tolist(), # marker={'color': 'blue', 'symbol': 'star', 'size': 10},\n",
    "                        mode='line', name=l)\n",
    "                 )\n",
    "# data = [trace, trace2]\n",
    "# data = [trace2]\n",
    "data = traces\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title=title,\n",
    "              xaxis=dict(title=xlabel,\n",
    "                         tickformat='.2f'),\n",
    "              yaxis=dict(title=ylabel,\n",
    "                         tickformat='.2f'),\n",
    "              paper_bgcolor='rgba(0,0,0,0)',\n",
    "              plot_bgcolor='rgba(0,0,0,0)',\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "# fig.append_trace(trace2, 1, 1)\n",
    "py.iplot(fig, filename='styled-line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdkjhagsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to save to\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "# filenamestr = ''.join(['output/costobj_heatmap_difstartpoints_', 'ipopt', '_',\n",
    "#                            timestamp, '.png'])\n",
    "filenamestr = ''.join(['output/costobj_heatmap_tausequence_', 'ipopt', '_',\n",
    "                           timestamp, '.png'])\n",
    "savefilepathandname = os.path.join(projectpath, filenamestr)\n",
    "\n",
    "# heatmap_costobj(df=df_piv, savefilepathandname=None, xname='startpointiterate')\n",
    "heatmap_costobj(df=df_piv, figsize=(10,100),\n",
    "                savefilepathandname=savefilepathandname, xname='tau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.edgecolor': '.8',\n",
    "                            'axes.spines.right': False,\n",
    "                            'axes.spines.top': False,\n",
    "                            'grid.linestyle': ':'})\n",
    "\n",
    "# Calculate the maximum, so we can set the yaxis limit to it\n",
    "max_acres = 0\n",
    "all_bmps = set()\n",
    "for tauno in range(1, 10):\n",
    "    df2 = df[df['tau']==tauno].groupby(by=['landriversegment', 'bmpshortname'])[['acres']].sum().unstack('bmpshortname').fillna(0)\n",
    "    \n",
    "    # For stacked bar graph\n",
    "    currmax = df2.sum(axis=1).max()\n",
    "    # For non-stacked\n",
    "#     currmax = ceil(df2.values.max())\n",
    "    if currmax > max_acres:\n",
    "        max_acres = currmax\n",
    "        \n",
    "    [all_bmps.add(x) for x in df2.columns.get_level_values('bmpshortname')]\n",
    "print(all_bmps)\n",
    "# Use the nice tableau color palette\n",
    "flatui = [\"#4e79a7\", \"#f28e2b\", \"#e15759\", \"#76b7b2\", \"#59a14f\",\n",
    "          \"#edc948\", \"#b07aa1\", \"#ff9da7\", \"#9c755f\", \"#bab0ac\"]\n",
    "sns.set_palette(sns.color_palette(flatui))  # set the color palette\n",
    "\n",
    "        # Make the figures\n",
    "for tauno in range(1, 10):\n",
    "    df2 = df[df['tau']==tauno].groupby(by=['landriversegment', 'bmpshortname'])[['acres']].sum().unstack('bmpshortname').fillna(0)\n",
    "    \n",
    "    # reset the column indices as regular columns\n",
    "    levels = df2.columns.levels\n",
    "    labels = df2.columns.labels\n",
    "    df2.columns = levels[1][labels[1]]\n",
    "    \n",
    "    # add columns for bmps that are all zeros\n",
    "    for bmpname in all_bmps:\n",
    "        if bmpname not in df2:\n",
    "            df2[bmpname] = 0\n",
    "    df2 = df2[list(all_bmps)]  # reorder so that each tau is the same order\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    ax=fig.gca()\n",
    "    p1 = df2.plot(ax=ax, kind='bar', stacked=True)\n",
    "    ax.set_ylabel('acres')\n",
    "    ax.set_title('Tau==%d' % tauno)\n",
    "    ax.set_ylim([0, max_acres])\n",
    "    ax.xaxis.grid(False)\n",
    "    \n",
    "#     print(ax.get_xlim()[1])\n",
    "#     p1.patches[1].set_facecolor('b')\n",
    "#     [rect.set_facecolor('b') for (i, rect) in enumerate(p1.patches) if (i%7==0)]\n",
    "\n",
    "    # Filepath to save to\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "    filenamestr = ''.join(['output/costobj_aggbars_tauno', str(tauno),'_ipopt', '_',\n",
    "                               timestamp, '.png'])\n",
    "    savefilepathandname = os.path.join(projectpath, filenamestr)\n",
    "    plt.savefig(savefilepathandname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import iplot\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')\n",
    "\n",
    "df2 = df[df['tau']==1].groupby(by=['landriversegment', 'bmpshortname'])[['acres']].sum().unstack('bmpshortname').fillna(0)\n",
    "display(df2.head(2))\n",
    "df2.iplot(kind='bar', barmode='stack', filename='stacked-bar-chart.png')\n",
    "# py.image.save_as(fig, filename='a-simple-plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "heights = {}\n",
    "\n",
    "for tii in range(2, 10):\n",
    "#     grouped = df[df['tau']==tii].groupby(by=['bmpshortname', 'landriversegment'])[['acres', 'totalinstancecost']].sum()\n",
    "    df2 = df[df['tau']==tii].groupby(by=['landriversegment', 'bmpshortname'])[['acres']].sum().unstack('bmpshortname').fillna(0)\n",
    "    fig = plt.figure()\n",
    "    p2 = df2.plot(ax=fig.gca(), kind='bar', stacked=True)\n",
    "    heights[tii-1] = [p.get_height() for p in p2.patches]\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "# grouped = df[df['tau']==1].groupby(by=['bmpshortname', 'landriversegment'])[['acres', 'totalinstancecost']].sum()\n",
    "df2 = df[df['tau']==1].groupby(by=['landriversegment', 'bmpshortname'])[['acres']].sum().unstack('bmpshortname').fillna(0)\n",
    "p1 = df2.plot(ax=fig.gca(), kind='bar', stacked=True)\n",
    "plt.show()\n",
    "heights[0] = [p.get_height() for p in p1.patches]\n",
    "\n",
    "def init():\n",
    "    return [p for p in p1.patches]\n",
    "\n",
    "def animate(i):\n",
    "    for rect, y in zip(p1.patches, heights[i]):\n",
    "        rect.set_height(y)\n",
    "    return rect,\n",
    "\n",
    "anim = FuncAnimation(fig,animate,init_func=init,frames=9,interval=500,blit=False)\n",
    "\n",
    "# Filepath to save to\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "filenamestr = ''.join(['output/costobj_animation_tausequence_', 'ipopt', '_',\n",
    "                           timestamp, '.mp4'])\n",
    "savefilepathandname = os.path.join(projectpath, filenamestr)\n",
    "anim.save(savefilepathandname, fps=2, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return ordered unique values\n",
    "def f5(seq, idfun=None): \n",
    "   # order preserving\n",
    "   if idfun is None:\n",
    "       def idfun(x): return x\n",
    "   seen = {}\n",
    "   result = []\n",
    "   for item in seq:\n",
    "       marker = idfun(item)\n",
    "       # in old Python versions:\n",
    "       # if seen.has_key(marker)\n",
    "       # but in new ones:\n",
    "       if marker in seen: continue\n",
    "       seen[marker] = 1\n",
    "       result.append(item)\n",
    "   return result\n",
    "\n",
    "combospresent = f5(zip(df.bmpshortname, df.loadsource))\n",
    "unique_lrsegs = set(df.lrsegs)\n",
    "unique_bmpnames = set(df.bmpshortname)\n",
    "unique_lsnames = f5(df.loadsource)\n",
    "\n",
    "nvarsperbmp = {b:None for b in unique_bmpnames}\n",
    "for b in unique_bmpnames:\n",
    "    nvarsperbmp[b] = len([x for x in combospresent if (x[0]==b)])\n",
    "maxvarsofabmp = max(nvarsperbmp.values())\n",
    "print(maxvarsofabmp)\n",
    "\n",
    "sorted_keys = sorted(nvarsperbmp.items(), key=lambda x: x[1])\n",
    "unique_bmpnames = list(x[0] for x in sorted_keys)\n",
    "print(sorted_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can ask for ALL THE AXES and put them into axes\n",
    "fig, axes = plt.subplots(nrows=len(unique_bmpnames), ncols=maxvarsofabmp, sharex=True, sharey=True, figsize=(18,10))\n",
    "axes_list = [item for sublist in axes for item in sublist] \n",
    "\n",
    "# ordered_var_names = df.groupby(by=['bmpshortname', 'loadsource'])['acres'].last().sort_values(ascending=False).index\n",
    "        \n",
    "from itertools import product\n",
    "all_possibles = list(product(unique_bmpnames, unique_lsnames))\n",
    "ordered_var_names = []\n",
    "for posspair in all_possibles:\n",
    "    if posspair in combospresent:\n",
    "        ordered_var_names.append(posspair)\n",
    "\n",
    "# Now instead of looping through the groupby\n",
    "# you CREATE the groupby\n",
    "# you LOOP through the ordered names\n",
    "# and you use .get_group to get the right group\n",
    "grouped = df.groupby(by=['bmpshortname', 'loadsource'])\n",
    "\n",
    "first_x = df['tau'].min()\n",
    "last_x = df['tau'].max()\n",
    "\n",
    "max_acres = df['acres'].max()\n",
    "\n",
    "i = {b:0 for b in unique_bmpnames}  # an empty dictionary of indices\n",
    "\n",
    "for varname in ordered_var_names:\n",
    "    selection = grouped.get_group(varname)\n",
    "    display(selection.tail(5))\n",
    "\n",
    "#     ax = axes_list.pop(0)\n",
    "    bidx = unique_bmpnames.index(varname[0])\n",
    "    ax = axes[bidx, i[varname[0]]]\n",
    "    if i[varname[0]] == 0:\n",
    "        ax.set_ylabel(varname[0], rotation=0, horizontalalignment='right')\n",
    "    i[varname[0]] += 1\n",
    "    axes_list.remove(ax)\n",
    "    \n",
    "    selection.plot(x='tau', y='acres', label=varname, ax=ax, legend=False)\n",
    "    ax.fill_between(x=selection['tau'],y1=0,y2=selection['acres'],color='#cec6b9')\n",
    "    \n",
    "    ax.set_title(varname[1])\n",
    "    ax.tick_params(\n",
    "        which='both',\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        right=False,\n",
    "        top=False\n",
    "    )\n",
    "    ax.grid(linewidth=0.25)\n",
    "    ax.set_xlim((first_x, last_x))\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticks((first_x, last_x))\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    max_constraint = selection['tau'].max()\n",
    "    \n",
    "    print(max_constraint)\n",
    "    print((selection.loc[df['tau'] == max_constraint]['acres']))\n",
    "    acres_value = float(selection.loc[df['tau'] == max_constraint]['acres'])\n",
    "    ax.set_ylim((0, max_acres))\n",
    "    ax.scatter(x=[max_constraint], y=[acres_value], s=60, clip_on=False, linewidth=0)\n",
    "#     ax.annotate(str(int(gdp_value / 1000)) + \"k\", xy=[max_year, gdp_value], xytext=[7, -2], textcoords='offset points')\n",
    "\n",
    "# Now use the matplotlib .remove() method to \n",
    "# delete anything we didn't use\n",
    "for ax in axes_list:\n",
    "    ax.remove()\n",
    "    \n",
    "fig.text(0.5, 0.00, 'Percent Load Reduction Lower Bound', ha='center')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=1)\n",
    "\n",
    "filenamestr = ''.join(['output/costobj_smallmult_tausequence_', 'ipopt', '_',\n",
    "                           datetime.now().strftime('%Y-%m-%d_%H%M%S'), '.png'])\n",
    "savefilepathandname = os.path.join(projectpath, filenamestr)\n",
    "plt.savefig(savefilepathandname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "parallel_coordinates(df_piv.drop('range', axis=1),\n",
    "                     class_column='tau', colormap='viridis')\n",
    "\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly Parallel Coordinates Plot (that doesn't work because the xaxis labels overlap, and there's no way to rotate them!!)\n",
    "\n",
    "# print(df_piv['tau'].max(skipna=True))\n",
    "# print(type(df_piv['tau'].max(skipna=True)))\n",
    "\n",
    "# # print([np.nanmax(df_piv[x]) for x in list(df_piv[df_piv.columns.difference(['tau', 'range'])].columns.values)])\n",
    "# data = [\n",
    "#     go.Parcoords(\n",
    "#         line = dict(color = df_piv['tau'],\n",
    "#                     colorscale='Jet',\n",
    "# #                     colorscale = [[0,'#D7C16B'],[0.5,'#23D8C3'],[1,'#F3F10F']],\n",
    "#                    showscale=True),\n",
    "#         dimensions = list([\n",
    "#             dict(range=(0, np.nanmax(df_piv[x])), \n",
    "#                  label=str(x), \n",
    "#                  values=df_piv[x])\n",
    "#             for x in list(df_piv[df_piv.columns.difference(['tau', 'range'])].columns.values)\n",
    "#         ])\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# layout = go.Layout(\n",
    "#     plot_bgcolor = '#E5E5E5',\n",
    "#     paper_bgcolor = '#E5E5E5',\n",
    "#     xaxis=dict(tickangle = 90),\n",
    "# )\n",
    "\n",
    "# fig = go.Figure(data = data, layout = layout)\n",
    "# py.iplot(fig, filename = 'parcoords-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:OptSubProblem]",
   "language": "python",
   "name": "conda-env-OptSubProblem-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
